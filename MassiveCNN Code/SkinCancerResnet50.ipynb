{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SkinCancerResnet50.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNlYf5xNhS5yG5A2bx+iwvm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"TYovUt-pNLfx"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LjlPn6RcNPkf"},"source":["from keras.layers import Input, Lambda, Dense, Flatten\n","from keras.models import Model\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","from tensorflow.keras.applications.resnet50 import preprocess_input\n","from keras.preprocessing import image\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","import numpy as np\n","from glob import glob\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# re-size all the images to this\n","IMAGE_SIZE = [224, 224]\n","\n","train_path = '/content/drive/MyDrive/SkinCancer/input/train'\n","valid_path = '/content/drive/MyDrive/SkinCancer/input/test'\n","\n","# add preprocessing layer to the front of VGG\n","resnet = ResNet50(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n","\n","# don't train existing weights\n","for layer in resnet.layers:\n","  layer.trainable = False\n","  \n","data_aug = False\n","  \n","  # useful for getting number of classes\n","folders = glob('/content/drive/MyDrive/SkinCancer/input/train/*')\n","  \n","\n","# our layers - you can add more if you want\n","x = Flatten()(resnet.output)\n","x = Dense(128, activation='relu')(x)\n","prediction = Dense(len(folders), activation='softmax')(x)\n","\n","# create a model object\n","model = Model(inputs=resnet.input, outputs=prediction)\n","\n","# view the structure of the model\n","model.summary()\n","\n","# tell the model what cost and optimization method to use\n","model.compile(\n","  loss='categorical_crossentropy',\n","  optimizer='adam',\n","  metrics=['accuracy']\n",")\n","\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","\n","train_datagen = ImageDataGenerator(rescale = 1./255,\n","                                   shear_range = 0.2,\n","                                   zoom_range = 0.2,\n","                                   horizontal_flip = True)\n","\n","test_datagen = ImageDataGenerator(rescale = 1./255)\n","\n","training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/SkinCancer/input/train',\n","                                                 target_size = (224, 224),\n","                                                 batch_size = 32,\n","                                                 class_mode = 'categorical')\n","\n","test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/SkinCancer/input/test',\n","                                            target_size = (224, 224),\n","                                            batch_size = 32,\n","                                            class_mode = 'categorical')\n","\n","'''r=model.fit_generator(training_set,\n","                         samples_per_epoch = 8000,\n","                         nb_epoch = 5,\n","                         validation_data = test_set,\n","                         nb_val_samples = 2000)'''\n","if data_aug:\n","  # fit the model\n","  print (\"Training with data augmentation\")\n","  r = model.fit_generator(\n","    training_set,\n","    validation_data=test_set,\n","    epochs=5,\n","    steps_per_epoch=len(training_set),\n","    validation_steps=len(test_set)\n","  )\n","else:\n","  print (\"Training with early stop\")\n","  monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=10, verbose=1, mode='auto', restore_best_weights=True)\n","  # fit model\n","  history = model.fit(training_set, epochs=200, batch_size=20, validation_data=test_set, verbose=1, callbacks=[monitor])\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cdYPavNMT2g2"},"source":["# loss\n","plt.plot(history.history['loss'], label='train loss')\n","plt.plot(history.history['val_loss'], label='val loss')\n","plt.savefig('/content/drive/MyDrive/Models_100/ResNet50/LossVal_ResNet50_loss128.png')\n","plt.legend()\n","plt.show()\n","\n","\n","# accuracies\n","plt.plot(history.history['accuracy'], label='train acc')\n","plt.plot(history.history['val_accuracy'], label='val acc')\n","plt.savefig('/content/drive/MyDrive/Models_100/ResNet50/AccVal_ResNet50_loss128.png')\n","plt.legend()\n","plt.show()\n","\n","\n","import tensorflow as tf\n","\n","from keras.models import load_model\n","\n","model.save('/content/drive/MyDrive/Models_100/ResNet50/Resnet50_128.h5')\n"],"execution_count":null,"outputs":[]}]}